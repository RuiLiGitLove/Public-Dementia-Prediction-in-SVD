{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from preprocessing_utils import calculate_feature, adjust_skewness_for_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use baseline data to fill NA in longitudinal data (No need to run again)\n",
    "(as there are more patients in the longitudinal data) If the feature to merge is NA in longitudinal data but not NA in baseline data, replace with the value in baseline data. If there is a mismatch, report the mismatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222ea75-56ac-4c76-8667-906512ed5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_long_data = pd.read_csv(\"../OPTIMAL_Data/SCANS/Handover_SCANS/SCANS_long.csv\", header=0)\n",
    "scans_long_data = scans_long_data.iloc[:, 1:]\n",
    "long_patient_IDs = np.unique(np.array(scans_long_data['ID']))\n",
    "no_patients_long = len(long_patient_IDs)\n",
    "\n",
    "scans_BL_data = pd.read_csv(\"../OPTIMAL_Data/SCANS/Handover_SCANS/Lawrence_2013_Baseline_Spreadsheet_complete_final.csv\", header=0)\n",
    "scans_BL_data = scans_BL_data.iloc[:, 1:]\n",
    "BL_patient_IDs = [int(i[2:]) for i in scans_BL_data['ID']] \n",
    "BL_patient_IDs = np.unique(np.array(BL_patient_IDs))\n",
    "\n",
    "\n",
    "no_patients_BL = len(BL_patient_IDs)\n",
    "print('There are {} patients in the longitudinal data, and {} patients in the baseline data. Additional patients in longitudinal data are {}'\n",
    "      .format(no_patients_long, no_patients_BL, set(long_patient_IDs) - set(BL_patient_IDs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9f3ef-0597-49ff-be2d-0ff8fa88ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_merge = ['PSMD', 'EF', 'PS']\n",
    "long_dict = {\n",
    "    'PSMD': 'psmd_value_long',\n",
    "    'EF': 'EF',\n",
    "    'PS': 'PS'\n",
    "}\n",
    "BL_dict = {\n",
    "    'PSMD': 'psmd_value_t0',\n",
    "    'EF': 'EF_t0',\n",
    "    'PS': 'PS_t0'\n",
    "}\n",
    "for ID in BL_patient_IDs:\n",
    "    if ID in long_patient_IDs:\n",
    "        long_patient_data = scans_long_data.loc[(scans_long_data['ID']==ID) & (scans_long_data['TP']==0)]\n",
    "        BL_patient_data = scans_BL_data.loc[scans_BL_data['ID']== ('ID'+ str(ID))]\n",
    "        \n",
    "        for feature in features_to_merge:\n",
    "            long_feature_value = long_patient_data.iloc[0][long_dict[feature]]\n",
    "            BL_feature_value = BL_patient_data.iloc[0][BL_dict[feature]]\n",
    "            if (pd.isna(long_feature_value)==True) and (pd.isna(BL_feature_value)==False): # Replace NA in longitudinal data\n",
    "                print('Replaced value for patient {} for feature {}'.format(ID, feature))\n",
    "                scans_long_data.loc[(scans_long_data['ID']==ID) & (scans_long_data['TP']==0), long_dict[feature]] = BL_feature_value\n",
    "            elif (pd.isna(long_feature_value)==False) and (pd.isna(BL_feature_value)==False): \n",
    "                try:\n",
    "                    long_feature_value-BL_feature_value < 1e-6\n",
    "                except:\n",
    "                    print(\"Mismatch for feature {}. Longitudinal: {}, baseline: {}\".format(feature, long_feature_value, BL_feature_value))\n",
    "            elif (pd.isna(long_feature_value)==False) and (pd.isna(BL_feature_value)==True):\n",
    "                print('Patient {} has non-NA value for feature {} only in longitudinal data.'.format(ID, ))\n",
    "            else:\n",
    "                continue\n",
    "    else:\n",
    "        print('Patient {} is not in longitudinal dataset.'.format(ID))\n",
    "\n",
    "## Sanity Check\n",
    "assert pd.isna(scans_long_data.loc[(scans_long_data['ID']==133) & (scans_long_data['TP']==0)].iloc[0]['psmd_value_long']) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scans_filled_BL_data = scans_long_data.loc[scans_long_data['TP']==0]\n",
    "# scans_filled_BL_data.to_csv(\"/Users/lirui/Downloads/gmlvq-python-rui/OPTIMAL_Data/SCANS/SCANS_filled_BL_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in (Filled) Baseline Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_filled_BL_data = pd.read_csv(\"../Cohort_Data/SCANS/SCANS_filled_BL_data.csv\", header=0)\n",
    "long_patient_IDs = np.unique(np.array(scans_filled_BL_data['ID']))\n",
    "num_patients_long = len(long_patient_IDs)\n",
    "\n",
    "print('There are {} patients in total'.format(num_patients_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select variables, using patient IDs in longitudinal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a917639e-bd56-4b7f-aab3-62b776b90b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_variable_dict = {\n",
    "    'WMH_vol_ml': ['WMH_ml'],\n",
    "    'num_lacunes':['lacunes'],\n",
    "    'num_mb': ['microbleeds'],\n",
    "    'TBV_ml': ['TCV_ml'], #defined as the sum of grey matter, white matter and WMH\n",
    "    'WM_vol_ml': ['sum', 'NAWM_ml', 'WMH_ml'],\n",
    "    'GM_vol_ml': ['GM_ml'],\n",
    "    'PSMD': ['psmd_value_long'],\n",
    "    'global_cog': ['Global'],\n",
    "    'EF': ['EF'],\n",
    "    'PS': ['PS'],\n",
    "    'age': ['BSL_age'],\n",
    "    'edu_yrs': ['education_years'],\n",
    "    'SVDp': ['SVDp'],\n",
    "    'BMI': ['BMI'],\n",
    "    'MMSE': ['MMSE'],\n",
    "    'T_survival': ['Time_dementia']\n",
    "}\n",
    "\n",
    "categorical_variable_dict = {\n",
    "    'sex': {\n",
    "        'name': 'sex',\n",
    "        'mapping':{\n",
    "            'male': 0,\n",
    "            'female': 1}\n",
    "    },\n",
    "    'HTN': {\n",
    "        'name': 'HTN',\n",
    "        'mapping':{\n",
    "            'No': 0,\n",
    "            'Yes': 1}\n",
    "    },\n",
    "    'HC': {\n",
    "        'name': 'HL',\n",
    "        'mapping':{\n",
    "            'No': 0,\n",
    "            'Yes': 1}\n",
    "    },\n",
    "    'diabetes': {\n",
    "        'name': 'diabetes',\n",
    "        'mapping': {\n",
    "            'non diabetic': 0,\n",
    "            'diabetic': 1,\n",
    "            'diet control': 1}\n",
    "    },\n",
    "    'smoking': {\n",
    "        'name': 'smoking',\n",
    "        'mapping': {\n",
    "            'never smoked': 0,\n",
    "            'current smoker': 1,\n",
    "            'ex-smoker': 1}\n",
    "    },\n",
    "    'dementia_final': {\n",
    "        'name': 'Dementia',\n",
    "        'mapping': {\n",
    "            'censored, no dementia': 0,\n",
    "            'developed dementia': 1}\n",
    "    }\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "for idx, ID in enumerate(long_patient_IDs):\n",
    "    this_patient_output_data = {'ID': ID}\n",
    "    patient_BL_data = scans_filled_BL_data.loc[scans_filled_BL_data['ID']==ID].iloc[0]\n",
    "\n",
    "    for output_feature in list(numeric_variable_dict.keys()):\n",
    "        if len(numeric_variable_dict[output_feature])>1: # combine features\n",
    "                operation = numeric_variable_dict[output_feature][0]\n",
    "                required_feature_names = numeric_variable_dict[output_feature][1:]\n",
    "                feature_value, contains_NA, NA_features = calculate_feature(operation, required_feature_names, patient_BL_data, [], False, output_feature)\n",
    "        else:\n",
    "            feature_value = patient_BL_data[numeric_variable_dict[output_feature][0]]\n",
    "            if (output_feature == 'T_survival') and (pd.isna(feature_value)==False) and feature_value>5.2:\n",
    "                feature_value = 5.2\n",
    "        this_patient_output_data[output_feature] = feature_value\n",
    "\n",
    "    for output_feature in list(categorical_variable_dict.keys()):\n",
    "        orig_feature = categorical_variable_dict[output_feature]['name']\n",
    "        feature_cat = str(patient_BL_data[orig_feature])\n",
    "        try:\n",
    "            feature_value = categorical_variable_dict[output_feature]['mapping'][feature_cat]\n",
    "        except: #If cannot be mapped, take the feature as it is.\n",
    "            feature_value = patient_BL_data[orig_feature]\n",
    "        this_patient_output_data[output_feature] = feature_value\n",
    "\n",
    "    output_data.append(this_patient_output_data)\n",
    "\n",
    "output_df = pd.DataFrame(output_data)\n",
    "print(output_df.shape)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c884f8cd-f6b7-4659-b979-98bc6705e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/original_data/complete_SCANS_121_subjects.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_long = scans_filled_BL_data.set_index('ID')\n",
    "ID_list = list(output_df['ID'])\n",
    "\n",
    "assert orig_data_long.loc[ID_list,'SVDp'].dropna().to_list() == output_df['SVDp'].dropna().to_list()\n",
    "assert orig_data_long.loc[ID_list,'BMI'].dropna().to_list() == output_df['BMI'].dropna().to_list()\n",
    "orig_T_survival = orig_data_long.loc[ID_list,'Time_dementia'].to_list()\n",
    "capped_T_survival = [min(i, 5.2) for i in orig_T_survival]\n",
    "assert capped_T_survival == output_df['T_survival'].to_list()\n",
    "\n",
    "# try:\n",
    "#     orig_data_cog.loc[ID_list,'cognitiveindex11'].to_list() == augmented_df['global_cog_5yr'].to_list()\n",
    "# except:\n",
    "#     print(np.where((orig_data_cog.loc[ID_list,'cognitiveindex11'].to_numpy() == augmented_df['global_cog_5yr'].to_numpy()) == False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
