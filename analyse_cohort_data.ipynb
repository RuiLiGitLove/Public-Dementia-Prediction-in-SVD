{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from IPython.display import display\n",
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "from Utils.data_preparation import get_input_variables, get_feature_set\n",
    "from decimal import Decimal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missingness_in_data(data, variables):\n",
    "    N = data.shape[0]\n",
    "    missingness_results = {}\n",
    "    for var in variables:\n",
    "        data_for_var = data[var]\n",
    "        N_nonNA = data_for_var.dropna().shape[0]\n",
    "        N_NA = N - N_nonNA\n",
    "        # if N_NA == 0:\n",
    "        #     missingness_results[var] = N_NA\n",
    "        # else: \n",
    "        #     missingness_results[var] = '{} ({:.1f}%)'.format(N_NA, 100*N_NA/N)\n",
    "        missingness_results[var] = str(N_NA)\n",
    "    #missingness_results_df = pd.DataFrame.from_dict(missingness_results)\n",
    "    return missingness_results # Returns a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and define the selected variables\n",
    "datapaths = {\n",
    "    'RUN DMC': '/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/original_data/complete_RUN_DMC_503_subjects.csv',\n",
    "    'SCANS': '/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/original_data/complete_SCANS_121_subjects.csv',\n",
    "    'HARMONISATION': '/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/original_data/complete_HARMONISATION_265_subjects.csv'\n",
    "}\n",
    "\n",
    "all_cohort_results = {}\n",
    "for cohort in list(datapaths.keys()):\n",
    "    data = pd.read_csv(datapaths[cohort])\n",
    "    if cohort == 'RUN DMC':\n",
    "        variables = ['WMH_vol_ml', 'SVDp', 'WM_vol_ml', 'GM_vol_ml', 'TBV_ml', 'num_lacunes','num_mb', 'PSMD',\\\n",
    "        'global_cog', 'EF', 'PS',\\\n",
    "        'age', 'edu_yrs', 'sex', 'HTN', 'HC', 'diabetes', 'smoking', # 'BMI', 'stroke_history',\\\n",
    "        'dementia_final', 'T_survival']\n",
    "        vars_to_drop = []\n",
    "\n",
    "    elif cohort == 'SCANS':\n",
    "        variables = ['WMH_vol_ml', 'SVDp', 'WM_vol_ml', 'GM_vol_ml', 'TBV_ml', 'num_lacunes','num_mb', 'PSMD',\\\n",
    "        'global_cog', 'EF', 'PS',\\\n",
    "        'age', 'edu_yrs', 'sex', 'HTN', 'HC', 'diabetes', 'smoking', # 'BMI', 'stroke_history',\\\n",
    "        'dementia_final', 'T_survival']\n",
    "        vars_to_drop = []\n",
    "        \n",
    "    elif cohort == 'HARMONISATION':\n",
    "        variables = ['WMH_vol_ml', 'SVDp', 'WM_vol_ml', 'GM_vol_ml', 'TBV_ml', 'ICV_ml', 'num_lacunes','num_mb', 'PSMD',\\\n",
    "        'global_cog', 'EF', 'PS',\\\n",
    "        'age', 'edu_yrs', 'sex', 'HTN', 'HC', 'diabetes', 'smoking',\\\n",
    "        'dementia_final', 'T_survival']\n",
    "        vars_to_drop = []\n",
    "\n",
    "    else: \n",
    "        print('Unrecognised cohort!')\n",
    "\n",
    "    # if ('ICV_ml' in list(data.columns)) == False:\n",
    "    #     variables.remove('ICV_ml')\n",
    "\n",
    "    selected_data = data.dropna(subset=vars_to_drop)\n",
    "\n",
    "    results_for_cohort = get_missingness_in_data(selected_data, variables)\n",
    "\n",
    "    #Append additional information\n",
    "    results_for_cohort['N'] = data.shape[0]\n",
    "    #results_for_cohort['N_selected'] = selected_data.shape[0]\n",
    "\n",
    "    # results_for_cohort['N_complete'] = data[variables].dropna().shape[0]\n",
    "    all_cohort_results[cohort] = results_for_cohort\n",
    "\n",
    "all_cohort_results_df = pd.DataFrame.from_dict(all_cohort_results, orient='columns')\n",
    "display(all_cohort_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cohort_results_df.to_csv('/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/missingness_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get baseline data summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cont_variables = ['WMLL *', 'Num Lacunes *', 'Num MB *']\n",
    "binary_variables = ['Bin MB (%)', 'Female (%)', 'Hypertension (%)', 'Hypercholesterolemia (%)', 'Diabetes (%)', 'Smoking (%)', 'Stroke History (%)']\n",
    "var_type='original'\n",
    "input_feature_name_dict = {\n",
    "    'WMLL *':{'transformed': 'Trans_SVDp', 'original': 'SVDp'},\n",
    "    'WM':{'transformed': 'WM_vol_ml', 'original': 'WM_vol_ml'},\n",
    "    'GM':{'transformed': 'GM_vol_ml', 'original': 'GM_vol_ml'},\n",
    "    'TBV':{'transformed': 'TBV_ml', 'original': 'TBV_ml'},  \n",
    "    'Num Lacunes *':{'transformed': 'Trans_num_lacunes', 'original': 'num_lacunes'},\n",
    "    'Num MB *':{'transformed': 'Trans_num_mb', 'original': 'num_mb'},\n",
    "    'Bin MB (%)':{'transformed': 'mb_bin', 'original': 'mb_bin'},\n",
    "    'PSMD':{'transformed': 'Trans_PSMD', 'original': 'PSMD'},\n",
    "\n",
    "    'Global cognition':{'transformed': 'global_cog', 'original': 'global_cog'},\n",
    "    'EF':{'transformed': 'EF', 'original': 'EF'},\n",
    "    'PS':{'transformed': 'PS', 'original': 'PS'},\n",
    "\n",
    "    'Age':{'transformed': 'age', 'original': 'age'},\n",
    "    'Edu':{'transformed': 'edu_yrs', 'original': 'edu_yrs'},\n",
    "\n",
    "    'Female (%)':{'transformed': 'sex', 'original': 'sex'},\n",
    "    'Hypertension (%)':{'transformed': 'HTN', 'original': 'HTN'},\n",
    "    'Hypercholesterolemia (%)':{'transformed': 'HC', 'original': 'HC'},\n",
    "    'Diabetes (%)':{'transformed': 'diabetes', 'original': 'diabetes'},\n",
    "    'Smoking (%)':{'transformed': 'smoking', 'original': 'smoking'},\n",
    "\n",
    "    'BMI': {'transformed': 'BMI', 'original': 'BMI'},\n",
    "    'Stroke History (%)': {'transformed': 'stroke_history', 'original': 'stroke_history'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_input_variables_to_print, multi_FS_name, multi_var_description, multi_cat_feature_indices = get_feature_set('Multi')\n",
    "all_possible_variables = get_input_variables(multi_input_variables_to_print, 'transformed')\n",
    "all_possible_variables = all_possible_variables + ['T_survival', 'dementia_final']\n",
    "\n",
    "all_cohort_data = {\n",
    "    'RUN DMC': {\n",
    "        'datapath': '/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/augmented_data/augmented_complete_RUN_DMC_503_subjects.csv',\n",
    "        'variables_no_missing': [] #all_possible_variables # ['T_survival', 'dementia_final', 'PSMD']\n",
    "    },\n",
    "\n",
    "    'SCANS': {\n",
    "        'datapath': '/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/augmented_data/augmented_complete_SCANS_121_subjects.csv',\n",
    "        'variables_no_missing': [] #all_possible_variables # ['T_survival', 'dementia_final']\n",
    "    },\n",
    "\n",
    "    'HARMONISATION': {\n",
    "        'datapath': '/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/augmented_data/augmented_complete_HARMONISATION_265_subjects.csv',\n",
    "        'variables_no_missing': [] #all_possible_variables # ['T_survival', 'dementia_final', 'SVDp']\n",
    "    }\n",
    "}\n",
    "\n",
    "for cohort in list(all_cohort_data.keys()):\n",
    "    data = pd.read_csv(all_cohort_data[cohort]['datapath'])\n",
    "    all_cohort_data[cohort]['data'] = data.dropna(subset=all_cohort_data[cohort]['variables_no_missing'])\n",
    "\n",
    "all_cohort_data['POOLED'] = {}\n",
    "all_cohort_data['POOLED']['data'] = pd.concat([all_cohort_data['RUN DMC']['data'], all_cohort_data['SCANS']['data'], all_cohort_data['HARMONISATION']['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cohort_data_summary = {}\n",
    "\n",
    "for cohort in list(all_cohort_data.keys()):\n",
    "    cohort_data = all_cohort_data[cohort]['data']\n",
    "    all_cohort_data_summary[cohort] = {\n",
    "        'Sample size in survival analysis': cohort_data.shape[0],\n",
    "    }\n",
    "\n",
    "    all_cohort_data_summary[cohort]['Final dementia cases (%)'] = '{} ({}%)'.format(\n",
    "            cohort_data[cohort_data['dementia_final']==1].shape[0], \n",
    "            round((cohort_data[cohort_data['dementia_final']==1].shape[0]/cohort_data.shape[0])*100, 1),)\n",
    "    T_q1, T_q3 = np.percentile(cohort_data['T_survival'], [25 ,75])\n",
    "    all_cohort_data_summary[cohort]['Follow-up time in years [median]'] = '{:.1f} [{:.1f}, {:.1f}]'.format(np.median(cohort_data['T_survival']), T_q1, T_q3)\n",
    "    all_cohort_data_summary[cohort]['Follow-up time in years [mean]'] = '{:.1f} ({:.1f})'.format(np.mean(cohort_data['T_survival']), np.std(cohort_data['T_survival']))\n",
    "\n",
    "    # Get 3-year dementia outcome stats\n",
    "    classification_cohort_data = cohort_data.dropna(subset=['dementia_3yr'])\n",
    "    all_cohort_data_summary[cohort]['Sample size in classification analysis'] = classification_cohort_data.shape[0] \n",
    "    num_dementia_3yr = classification_cohort_data[classification_cohort_data['dementia_3yr']==1].shape[0]\n",
    "    all_cohort_data_summary[cohort]['3-year dementia cases (%)'] = '{} ({}%)'.format(\n",
    "        num_dementia_3yr,\n",
    "        round(num_dementia_3yr*100/classification_cohort_data.shape[0], 1)\n",
    "    )\n",
    "\n",
    "        \n",
    "    for idx, print_name in enumerate(list(input_feature_name_dict.keys())):\n",
    "        if (cohort in ['HARMONISATION', 'HARMONISATION_High_SVD', 'HARMONISATION_Low_SVD']) and (print_name in ['BMI', 'Stroke History (%)']):\n",
    "            continue\n",
    "        else:\n",
    "            variable = input_feature_name_dict[print_name][var_type]\n",
    "            values = cohort_data[variable].dropna()\n",
    "            \n",
    "            if print_name in skewed_cont_variables: # report median and IQR\n",
    "                median = np.median(values)\n",
    "                q1, q3 = np.percentile(values, [25,75])\n",
    "                if print_name != 'WMLL *':\n",
    "                    output = '{:.0f} [{:.0f}, {:.0f}]'.format(median, q1, q3)\n",
    "                else:\n",
    "                    output = '{:.2f} [{:.2f}, {:.2f}]'.format(median, q1, q3)\n",
    "            elif print_name in binary_variables: # report percentage of 1\n",
    "                count = np.sum(values)\n",
    "                mean = np.mean(values)\n",
    "                output = \"{} ({:.1f}%)\".format(int(count), mean*100)\n",
    "            else: # report mean and std\n",
    "                mean = np.mean(values)\n",
    "                std = np.std(values)\n",
    "                if variable == 'PSMD':\n",
    "                    output = \"{:.2E} ({:.2E})\".format(Decimal(mean), Decimal(std)) \n",
    "                else:            \n",
    "                    output = \"{:.2f} ({:.2f})\".format(mean, std)  \n",
    "            \n",
    "            all_cohort_data_summary[cohort][print_name] =  output\n",
    "\n",
    "all_cohort_data_summary_df = pd.DataFrame.from_dict(all_cohort_data_summary, orient='columns')\n",
    "display(all_cohort_data_summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cohort_data_summary_df.to_csv('/Users/lirui/Downloads/Cohort_Dementia_Prediction/Cohort_Data/Selected_Data/Data_6.0/data_summary.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = original_data\n",
    "data2 = classification_data\n",
    "\n",
    "for idx, feature in enumerate(all_possible_variables):\n",
    "    #Numerical features -- use Student's t test (equal_var=True) or Welch's t test (equal_var=False)\n",
    "    if feature in ['Trans_SVDp', 'num_lacunes', 'num_mb', 'TBV_ml', 'Trans_PSMD', 'global_cog', 'EF', 'PS', 'age', 'edu_yrs']:\n",
    "        array1 = data1[feature].to_numpy()\n",
    "        array2 = data2[feature].to_numpy()\n",
    "        p_val = ttest_ind(array1, array2, equal_var=True)[1]\n",
    "        if p_val <0.05:\n",
    "            print(feature, p_val)\n",
    "\n",
    "    # Binary features -- use chi squared test\n",
    "    elif feature in ['mb_bin', 'sex', 'HTN', 'HC', 'diabetes', 'smoking']:\n",
    "        data1['DS'] = 'DS1'\n",
    "        data2['DS'] = 'DS2'\n",
    "        df = pd.concat([data1[['DS', feature]], data2[['DS', feature]]])\n",
    "        table = pd.crosstab(index=df['DS'], columns=df[feature])\n",
    "        chi2, p, dof, expected = chi2_contingency(table)\n",
    "        if p < 0.05:\n",
    "            print(feature, p)\n",
    "    else:\n",
    "        print(feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
